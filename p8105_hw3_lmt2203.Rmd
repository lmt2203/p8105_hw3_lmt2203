---
title: "Homework 3"
author: "Linh Tran"
date: "10/6/2020"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,  
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom")) 

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_colour_continuous = scale_color_viridis_c
```

# Problem 1

Load the dataset

```{r}
library(p8105.datasets)
data("instacart")
print(instacart)
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns.

Observations are the level of items in orders by user. There are users / order variables â€“ user ID, order ID, order day, and order hour. There are also item variables â€“ name, aisle, department, and some numeric codes.

How many aisles, and which are most items from?

```{r}
instacart %>% 
  count(aisle) %>%
  arrange(desc(n))       
```

Let's make a plot shows the number of items ordered in each aisle

```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust = 1))
```

Let's make a table showing the three most popular items in each of the 3 listed aisles

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4 ) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

Make a table showing the mean hour of the day at which Pink Lady Apple and Coffee Ice Cream are ordred on each day of the week

```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```

# Problem 2

#### Load, tidy and wrangle the accelerometer dataset

```{r}
accel_df = read_csv("./data/accel_data.csv") %>% 
  pivot_longer(
    activity.1:activity.1440,
    names_to = "min_of_the_day",
    names_prefix = "activity.",
    values_to = "activity_count"
  ) %>% 
  mutate(day = factor(day)) %>% 
  mutate(wd_or_wknd = case_when(
        day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") ~ "weekday",
        day %in% c("Saturday", "Sunday") ~ "weekend",
         TRUE ~ "")
  ) %>% 
  mutate(min_of_the_day = factor(min_of_the_day),
         wd_or_wknd = factor(wd_or_wknd)
  )

accel_df
```


#### Aggregate across minutes to create a total activity variable for each day, and create a table showing these totals. Any trends?

```{r}

```

#### Make a single-panel plot that shows 24-hour activity time courses for each day and use color to indicate day of the week. Describe in words any patterns or conclusions you can make based on this graph

```{r}

```



# Problem 3

Load the data 

```{r}
library(p8105.datasets)
data("ny_noaa")
```

The dataset has `r ncol(ny_noaa)` variables, specifically  *`r names(ny_noaa)`* and `r nrow(ny_noaa)` observations. 

Data cleaning

```{r}
ny_noaa_tidy = ny_noaa %>% 
  separate(date, into = c("year", "month", "day"), sep = "-")
```

Last part: use `patchwork`

```{r}

```

#### Make a two-panel plot the average 

```{r}

```


x = tmin, y = tmax