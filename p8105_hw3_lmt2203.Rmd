---
title: "Homework 3"
author: "Linh Tran"
date: "10/6/2020"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,  
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom")) 

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_colour_continuous = scale_color_viridis_c
```

# Problem 1

Load the Instacart dataset

```{r}
library(p8105.datasets)
data("instacart")
print(instacart)
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns. 

Observations are the level of items in orders by user. There are users / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes.

How many aisles, and which are most items from?

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))        #descending order
```

Let's make a plot

```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust = 1))
```

Let's make a table

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetable fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4 ) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

Apple vs. ice cream

```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```

# Problem 2

Load and tidy the accelerometer dataset

```{r}
accel_df = read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names()
```

# Problem 3

Load the data 

```{r}
library(p8105.datasets)
data("ny_noaa")
ny_noaa
```

The dataset has `r ncol(ny_noaa)` variables, specifically  *`r names(ny_noaa)`* and `r nrow(ny_noaa)` observations. 

Data cleaning

```{r}
ny_noaa %>% 
  separate(date, into = c("year", "month", "day"), sep = "-")
```

