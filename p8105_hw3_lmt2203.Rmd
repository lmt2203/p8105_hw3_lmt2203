---
title: "Homework 3"
author: "Linh Tran"
date: "10/6/2020"
output: github_document
---

```{r setup}
library(tidyverse)
library(ggridges)
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 12,
  fig.asp = .6,  
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom")) 

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_colour_continuous = scale_color_viridis_c
```

# Problem 1

Load the dataset

```{r}
library(p8105.datasets)
data("instacart")
print(instacart)
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns.

Observations are the level of items in orders by user. There are users / order variables – user ID, order ID, order day, and order hour. There are also item variables – name, aisle, department, and some numeric codes.

How many aisles, and which are most items from?

```{r}
instacart %>% 
  count(aisle) %>%
  arrange(desc(n))       
```

Let's make a plot shows the number of items ordered in each aisle

```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust = 1))
```

Let's make a table showing the three most popular items in each of the 3 listed aisles

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4 ) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

Make a table showing the mean hour of the day at which Pink Lady Apple and Coffee Ice Cream are ordred on each day of the week

```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```

# Problem 2

#### Load, tidy and wrangle the accelerometer dataset

```{r}
accel_df = read_csv("./data/accel_data.csv") %>% 
  pivot_longer(
    activity.1:activity.1440,
    names_to = "min_of_the_day",
    names_prefix = "activity.",
    values_to = "activity_count"
  ) %>% 
  mutate(day = factor(day),
         day = forcats::fct_relevel(day, c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))) %>% 
  mutate(wd_or_wknd = case_when(
        day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") ~ "weekday",
        day %in% c("Saturday", "Sunday") ~ "weekend",
         TRUE ~ "")
  ) %>% 
  mutate(min_of_the_day = as.numeric(min_of_the_day),
         wd_or_wknd = factor(wd_or_wknd)
  )

accel_df
```

The dataset contains `r nrow(accel_df)` observations of `r ncol(accel_df)` variables, including *week*, *day_id*, *min_of_the_day* show each minute of the day for the 5 weeks that data were collected, *activity_count* for each minute, and  *wd_or_wknd* variable that tells you if a given day is weekday or weekend. 

#### Table showing total activity for each day of the 5 weeks

```{r}
accel_df %>% 
  group_by(week, day) %>% 
  summarize(total_activity_each_day = sum(activity_count)) %>% 
  pivot_wider(
    names_from = day,
    values_from = total_activity_each_day) %>% 
   knitr::kable(digit = 1) 
```

We can see from the table that Saturdays seem to have the widest range of activity count, from 1440 to 607175 while Tuesdays-Thursdays have a relatively small variance in activity count. The least activity count is 1440 on Saturdays of week 4 and week 5 while the highest activity count is 685910 on Monday of week 3. Overall, the man whose accelerometer data we are looking at are consistenly active during midweek.

#### Single-panel plot that shows 24-hour activity time courses for each day 

```{r}
accel_df %>%  
  ggplot(aes(x = min_of_the_day, y = activity_count, color = day)) +
  geom_line(size = 1.5, alpha = .6) +  
  geom_smooth() +
  stat_smooth()
  labs(title = "24-hour activity time courses",
       x = "Minute of the day",
       y = "Activity count",
       caption = "5-week activity count from a 63 year-old male, BMI = 25, diagnosed with congestive heart failure") 
```

Based on this graph we could see that the man generally has low activity at night time (midnight to ~6-7am), then higher activity at day time and drop back down in the evening. He is highly active during the day on Sunday, and much more active late evening on Friday/Saturday. Other days of the week show lots of overlapping, meaning he is more routine during mid-week. 

# Problem 3
Load the NY NOAA dataset

```{r}
library(p8105.datasets)
data("ny_noaa")
```

The NY NOAA dataset contains data collectd from all New York state weather stations from January 1, 1981 to December 31, 2010. It has `r nrow(ny_noaa)` observations of `r ncol(ny_noaa)` variables, specifically  *`r names(ny_noaa)`*. Variable ID show weather station ID; prcp, snow, snwd, tmax, tmin are precipitation (mm), snowfall(mm), snow depth(mm), maximum temperature(tenths of degrees C), and minimum temperature(tenths of degrees C) of a given date, respectively. There are lots of missing values: the number of missing values for precipitation, snowfall, snow depth, min temp, max temp are `r sum(is.na(ny_noaa$prcp))`, `r sum(is.na(ny_noaa$snow))`, `r sum(is.na(ny_noaa$snwd))`, `r sum(is.na(ny_noaa$tmax))`, `r sum(is.na(ny_noaa$tmin))` respectively.

#### Data cleaning

```{r}
ny_noaa_df = 
  ny_noaa %>% 
  separate(date, into = c("year", "month", "day"), sep = "-", convert = TRUE) %>% 
  mutate(
    tmax = as.numeric(tmax)/10,
    tmin = as.numeric(tmin)/10,
    prcp = as.numeric(prcp),
    snow = as.numeric(snow),
    snwd = as.numeric(snwd))

snow_count = 
  ny_noaa_df %>% 
  drop_na() %>% 
  group_by(snow) %>% 
  summarize(snow_count = n()) %>% 
  arrange(desc(snow_count))

snow_count
```

The most commonly observed value for snowfall is **0**, with 1112758 days reported no snow. This seems reasonable considering for the majority time of a year, New York doesn't have any snow. The second most common value is 25 and third most common is 13. 

#### Two-panel plot showing the average max temperature in January and July in each station across years

```{r, warning = FALSE}
jan_july_tmax = 
  ny_noaa_df %>% 
  filter(month %in% c("1", "7")) %>%
  group_by(id, year, month) %>% 
  summarize(mean_tmax = mean(tmax, na.rm = TRUE)) %>% 
  mutate(month = recode(month, `1` = "January", `7` = "July"))

ggplot(jan_july_tmax, aes(x = year, y = mean_tmax, group = id, color = id)) +
  geom_point() +
  geom_path() +
  facet_grid(~ month) +
  labs(title = "Average max temperature for January and July across stations and years",
       x = "Year",
       y = "Average Max Temperature (C)") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  theme(legend.position = "none")
```

Average max temperature in January ranging from -10C to 10C is lower than average max temperature in July, which is in the 20-30 degree Celcius range. There are several noticeable outliers, particularly January of 1982 where the average max temperature is much lower than -10C and July of 1987 where average max temperature is unusually low (~13-14C).

#### Two-panel plot showing (1) tmax vs tmin for full dataset and (2) distribution of snowfall greater than 0 and less than 100

```{r, warning = FALSE}
tmax_tmin_plot = 
  ny_noaa_df %>% 
  drop_na(tmax, tmin) %>% 
  ggplot(aes(x = tmin, y = tmax)) +
  geom_density2d() +
  labs(
    title = "Maximum vs Minimum Temperatures from 1981 to 2010",
    x = "Minimum Temperature",
    y = "Maximum Temperature")
  
snow_fall_plot =
  ny_noaa_df %>% 
  filter(snow > 0 & snow < 100) %>% 
  ggplot(aes(x = snow, y = as.factor(year))) +
  geom_density_ridges(alpha = .3, adjust = .5) +
  labs(
    title = "Distribution of Snowfall from 1981 to 2010",
    x = "Snowfall (mm)",
    y = "Year") +
  scale_x_continuous(breaks = c(0, 25, 50, 75, 100, 125, 150, 175))

tmax_tmin_plot / snow_fall_plot
```

